# Kaggle Blue Book Bulldozers Competition Project

## Overview

Tree-based models like Random Forest and XGBoost have become very popular in solving tabular(structured) data problems and gained a lot of tractions in Kaggle competitions lately. It has its very deserving reasons. However, in this article, I want to introduce a different approach from fast.ai’s **Tabular** module leveraging:
> **Deep Learning and Embedding Layers.**

This is a bit against industry consensus that Deep Learning is more for unstructured data like image, audio or NLP, and usually not suitable for handling tabular data. Yet, the introduction of embedding layers for the categorical data changed this perspective and we’ll try to use[ fast.ai](http://fast.ai)’s tabular module on the [Blue Book Bulldozers Competition](https://www.kaggle.com/c/bluebook-for-bulldozers/overview) on [Kaggle](http://kaggle.com) and see how far this approach can go.

## Notebook

You can find the **Jupyter Notebook** ![here](https://github.com/wayofnumbers/Kaggle-Blue-Book-Bulldozers-Competition-Project/blob/main/blue-book-bulldozer-fast-ai-deep-learning.ipynb).

If you want to give it a try, you can also find the Notebook on Kaggle where you can easily copy and run yourself(Dataset on Kaggle too):
**Kaggle Notebook** (https://www.kaggle.com/lymenlee/blue-book-bulldozer-fast-ai-deep-learning/notebook)

## Kaggle Competition

You can find the Kaggle Competition page here: (https://www.kaggle.com/c/bluebook-for-bulldozers)
The competition is over and closed, but you can still run the notebook and compare with the leaderboard results for reference.

## Article

I wrote two articles about this project on Medium.com, which you can find below:
**How to Gain State-Of-The-Art Result on Tabular Data with Deep Learning and Embedding Layers** (https://towardsdatascience.com/how-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c)

